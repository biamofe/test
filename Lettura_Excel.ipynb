{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leggo il file excel TdB\n",
    "df = pd.read_excel('/Users/federico/Desktop/TableauDeBoard/Tableau de Bord_Interim Master 30.11.2023.xlsb', sheet_name='TdB - Executive per ptf.',  skiprows=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estendo la visualizzazione del dataframe su righe e colonne\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([261], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#droppa le colonne che hanno nome Unnamed\n",
    "col_index = [index for index, col in enumerate(df.columns) if 'Unnamed' in str(col)]\n",
    "df.drop(df.columns[col_index], axis=1, inplace=True)\n",
    "\n",
    "#imposta il valore di df.loc[0, 'Current period:\\n2023;Q4;November 30 th'] a NaN\n",
    "df.loc[0, 'Current period:\\n2023;Q4;November 30 th'] = pd.NA\n",
    "\n",
    "\n",
    "\n",
    "#individua la riga delle Note e droppa dall'indice di quella riga in poi\n",
    "row_index = df[df['Current period:\\n2023;Q4;November 30 th'] == 'Notes: '].index\n",
    "print(row_index)\n",
    "df.drop(df.index[row_index[0]:], inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se individuo due righe consecutive che contengono NaN, allora ne droppo una\n",
    "indeces_to_drop = []\n",
    "count = 0\n",
    "for i, value in enumerate(df['Current period:\\n2023;Q4;November 30 th']):\n",
    "    if pd.isna(value) == False:\n",
    "        count = 0\n",
    "    else:\n",
    "        count += 1\n",
    "        if count == 2:\n",
    "            indeces_to_drop.append(i)\n",
    "\n",
    "df.drop(indeces_to_drop, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_segmentation(df):\n",
    "    indici_nan = df.index[df['Current period:\\n2023;Q4;November 30 th'].isna()].tolist()\n",
    "    segmenti = {}\n",
    "\n",
    "    for start, end in zip(indici_nan, indici_nan[1:] + [None]):\n",
    "        segmento = df.iloc[start+1:end]\n",
    "        if not segmento.empty:\n",
    "            nome_df = str(segmento.iloc[0, 0]).replace(' ', '_').replace(':', '').replace(';', '_').replace('\\n', '_').replace('.', '').replace('(', '').replace(')', '').replace('-', '_').replace('/', '_')\n",
    "            segmenti[nome_df] = segmento\n",
    "\n",
    "    return segmenti\n",
    "\n",
    "segmenti = auto_segmentation(df)\n",
    "lista_df = []\n",
    "for i in segmenti.keys():\n",
    "    exec(f'global df_{i}; df_{i} = segmenti[i]', globals())\n",
    "    exec(f'lista_df.append(df_{i})', globals())\n",
    "    exec(f'df_{i}.reset_index(drop=True, inplace=True)', globals())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RIMARREBBE INFINE DA SCARTARE LA CELLA RIASSUNTIVA PER I VARI SEGMENTI DI ALICUDI.\n",
    "\n",
    "UN ALTRO MODO DI FARE UN CHECK POTREBBE ESSERE QUELLO DI LEGGERE TUTTO E DI FARE UNA LEFT JOIN SU: NOME RIGA + IMPORTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_clusters(df):\n",
    "    i = 0\n",
    "    k = 0\n",
    "    tries = 0\n",
    "    clusters = []\n",
    "\n",
    "    while i < len(df):\n",
    "        # Valore di partenza per il cluster\n",
    "        valore_iniziale = df.iloc[i]['# Borrowers']\n",
    "        somma = valore_iniziale\n",
    "        j = i + 1\n",
    "\n",
    "        # Calcola la differenza cumulativa finché non raggiunge zero o la fine del DataFrame\n",
    "        while j < len(df) and somma != 0:\n",
    "            somma -= df.iloc[j]['# Borrowers']\n",
    "            j += 1\n",
    "            tries += 1\n",
    "\n",
    "        # Se la somma è zero, allora abbiamo trovato un cluster\n",
    "        if len(df) == 1:\n",
    "            clusters.append(df.iloc[0])\n",
    "            break\n",
    "        if somma == 0:\n",
    "            # Aggiungi il cluster al risultato\n",
    "            cluster = df.iloc[i:j]\n",
    "            clusters.append(cluster)\n",
    "            i = j-1\n",
    "            if k == 0:\n",
    "                j -= 1\n",
    "                if j == len(df) -1:\n",
    "                    if i < len(df) - 1:\n",
    "                        clusters.append(df.iloc[-1])\n",
    "                    else:\n",
    "                        break\n",
    "            if j != i+2 and i != 0:\n",
    "                i = j\n",
    "        elif tries > len(df):\n",
    "            clusters.append(df.iloc[-1])\n",
    "            break\n",
    "        else:\n",
    "            k += 1\n",
    "            i = k\n",
    "        \n",
    "\n",
    "    # Utilizzo l'hashing per identificare i dataframes duplicati\n",
    "    # Sommo gli hashing per ottenere un unico valore per ogni DataFrame\n",
    "    clusters_hashed = [pd.util.hash_pandas_object(x, index=True).sum() for x in clusters]\n",
    "\n",
    "    # Creiamo un set vuoto per tenere traccia degli hash unici\n",
    "    unique_hashes = set()\n",
    "    unique_clusters = []\n",
    "\n",
    "    for i, hash_value in enumerate(clusters_hashed):\n",
    "        if hash_value not in unique_hashes:\n",
    "            unique_clusters.append(clusters[i])\n",
    "            unique_hashes.add(hash_value)\n",
    "\n",
    "    # Ora unique_clusters contiene i DataFrame senza duplicati\n",
    "    clusters = unique_clusters\n",
    "\n",
    "\n",
    "\n",
    "    return clusters\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inserisco in una lista i risultati della clusterizzazione su tutti i DataFrame\n",
    "lista_clusters = []\n",
    "for i in range(len(lista_df)):\n",
    "    lista_clusters.append(match_clusters(lista_df[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clusters = []\n",
    "for cluster in lista_clusters:\n",
    "    if len(cluster) > 1:\n",
    "        for sub_cluster in cluster:\n",
    "            all_clusters.append(sub_cluster)\n",
    "    else:\n",
    "        all_clusters.append(cluster)\n",
    "\n",
    "for index, cluster in enumerate(all_clusters):\n",
    "    if len(cluster) == 0:\n",
    "        all_clusters.pop(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_title(df):\n",
    "    if isinstance(df, pd.DataFrame):\n",
    "        # Prima resetta l'indice del DataFrame\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        # Ora accedi alla prima riga in modo sicuro\n",
    "        title = df.loc[0, 'Current period:\\n2023;Q4;November 30 th']\n",
    "        print(title)\n",
    "        return title\n",
    "    elif isinstance(df, pd.Series):\n",
    "        title = df['Current period:\\n2023;Q4;November 30 th']\n",
    "        print(title)\n",
    "        return title\n",
    "    else:\n",
    "        return get_title(df[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_list = []\n",
    "for index, df in enumerate(all_clusters):\n",
    "    titles_list.append(get_title(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Total Full Portfolios',\n",
       " 'Total Full Ptf.s Intrum Italy',\n",
       " 'Total Proprietary',\n",
       " 'Total Proprietary Revalue',\n",
       " 'Revalue',\n",
       " 'Other Clients',\n",
       " 'o.w. Phone&Field Intrum Italy',\n",
       " 'Total Proprietary Intrum Italy',\n",
       " 'Total Proprietary Direct',\n",
       " 'Kenobi',\n",
       " 'Intrum - Saturnia',\n",
       " 'Intrum - West',\n",
       " 'Intrum - Elettra',\n",
       " 'Caterina',\n",
       " 'Jawa',\n",
       " 'Fantino',\n",
       " 'IJDF Italy',\n",
       " 'Intrum Debt AG',\n",
       " 'LSF WEST - REOCO',\n",
       " 'Arizona SPV Mandalorian',\n",
       " 'Arizona Oasis',\n",
       " 'Total Propriatery JV',\n",
       " 'TOP',\n",
       " 'Large',\n",
       " 'Medium',\n",
       " 'Small Secured',\n",
       " 'Small Unsecured',\n",
       " 'Not segmented',\n",
       " 'Savoy Reoco',\n",
       " 'Portland']"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles_list[0:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "j = 0\n",
    "while i < len(lista_df):\n",
    "    df1 = lista_df[i]\n",
    "    df2 = all_clusters[j]\n",
    "    joined_df = pd.merge(df1, df2, how='inner')\n",
    "    if len(joined_df) == len(df1):\n",
    "        j += 1\n",
    "        cluster = \n",
    "    else:\n",
    "        i += 1\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
